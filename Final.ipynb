{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contributors\n",
    "### Jay Upadhyay\n",
    "### Haruki Miyazaki\n",
    "### Victor Sandoval Vargas\n",
    "###\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig=pd.read_csv(\"adult.csv\")\n",
    "df_orig.dropna(inplace=True)\n",
    "df_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Project Proposal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pulled the data from https://archive-beta.ics.uci.edu/dataset/2/adult . The data from our dataset was collected through a US census. Using this dataset we will perform a cross examination between the relationship between class and race/sex. Class, in this dataset, is defined as either making <=50k or >50k as yearly income. We will create regression models to predict if an individual's race and sex determines if they are likely to be making over or under 50k. Prior to doing the analysis of the dataset, we will clean the data by making categorical values into numerical. An example of this is changing the values of class into 0 and 1, where 0 represents <=50k and 1 represents >50k. After data cleaning, we will create visuals to enhance our understanding of the story our dataset is telling. We will perform linear regression to use as a base for our other techniques deployed in this project. The advanced techniques we will perform in this analysis includes KNN and Random Forest Models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Collection and data cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that our dataset has many categorital data, we will clean it by converting to numerical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing workclass to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workclass_list = list(sorted(set(df_orig[\" workclass\"])))\n",
    "\n",
    "for i,x in enumerate(workclass_list):\n",
    "    print(i,\":\", x)\n",
    "    \n",
    "df_orig[' workclass'].replace(workclass_list,\n",
    "                        range(len(workclass_list)), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing Education to Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig['education'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_list=[ ' Preschool',' 1st-4th',' 5th-6th',' 7th-8th',' 9th',' 10th',' 11th',' 12th',' HS-grad',\n",
    "                              ' Assoc-voc',' Assoc-acdm',' Some-college',' Bachelors', ' Masters',\n",
    "                              ' Prof-school' ,' Doctorate']\n",
    "\n",
    "df_orig['education'].replace(education_list,\n",
    "                        range(16), inplace=True)\n",
    "\n",
    "df_orig\n",
    "for x in range(16):\n",
    "    print(x,\":\", education_list[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note. I want to come back to this and bin it into appropriate \n",
    "I also chose to exclude this for now because I believe education-num already represents it numerically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing marital status to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marital_list = list(sorted(set(df_orig[\"marital-status\"])))\n",
    "\n",
    "for i,x in enumerate(marital_list):\n",
    "    print(i,\":\", x)\n",
    "\n",
    "df_orig['marital-status'].replace(marital_list,\n",
    "                        range(len(marital_list)), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Occupation\n",
    "\n",
    "I don't like the ? mark section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupation_list = list(sorted(set(df_orig[\"occupation\"])))\n",
    "\n",
    "for i,x in enumerate(occupation_list):\n",
    "    print(i,\":\", x)\n",
    "\n",
    "df_orig['occupation'].replace(occupation_list,\n",
    "                        range(len(occupation_list)), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationship conversion to numeric\n",
    "\n",
    "I don't like other relative section here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship_list = list(sorted(set(df_orig[\"relationship\"])))\n",
    "\n",
    "for i,x in enumerate(relationship_list):\n",
    "    print(i,\":\", x)\n",
    "\n",
    "df_orig['relationship'].replace(relationship_list,\n",
    "                        range(len(relationship_list)), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race conversion to numeric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_list = list(sorted(set(df_orig[\"race\"])))\n",
    "\n",
    "for i,x in enumerate(race_list):\n",
    "    print(i,\":\", x)\n",
    "\n",
    "df_orig['race'].replace(race_list,\n",
    "                        range(len(race_list)), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sex conversion to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_list = list(sorted(set(df_orig[\"sex\"])))\n",
    "\n",
    "for i,x in enumerate(sex_list):\n",
    "    print(i,\":\", x)\n",
    "\n",
    "df_orig['sex'].replace(sex_list,\n",
    "                        range(len(sex_list)), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country to Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing a column \"class\" to be 0:<=50K and 1:>50K\n",
    "country_list = list(sorted(set(df_orig[\"native-country\"])))\n",
    "\n",
    "for i,x in enumerate(country_list):\n",
    "    print(i,\":\", x)\n",
    "\n",
    "df_orig['native-country'].replace(country_list,\n",
    "                        range(len(country_list)), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Income to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing a column \"class\" to be 0:<=50K and 1:>50K\n",
    "class_list = list(sorted(set(df_orig[\"class\"])))\n",
    "\n",
    "for i,x in enumerate(class_list):\n",
    "    print(i,\":\", x)\n",
    "    \n",
    "df_orig['class'].replace(class_list,\n",
    "                        range(len(class_list)), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig['education'].replace([ ' Preschool',' 1st-4th',' 5th-6th',' 7th-8th',' 9th',' 10th',' 11th',' 12th',' HS-grad',\n",
    "                               ' Assoc-voc',' Assoc-acdm','Some-college',' Bachelors', ' Masters',\n",
    "                               ' Prof-school' ,' Doctorate'],\n",
    "                         range(0,16), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Gender = df_orig[[\"sex\"]]\n",
    "Y_Income = df_orig[\"class\"]\n",
    "\n",
    "GenderIncome_model = LinearRegression()\n",
    "GenderIncome_model.fit(X=X_Gender, y=Y_Income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "X_GenderIncome = pd.DataFrame(df_orig)\n",
    "X_GenderIncome[\"sex\"] = np.linspace(0,1,num=32561)\n",
    "y_GenderIncome = pd.Series(\n",
    "    GenderIncome_model.predict(X_GenderIncome),\n",
    "    index = X_GenderIncome[\"sex\"]\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FemaleIncome = GenderIncome_model.predict( X=[[0]] )[0]\n",
    "MaleIncome = GenderIncome_model.predict( X=[[1]])[0]\n",
    "condition = \"\"\n",
    "if MaleIncome > FemaleIncome:\n",
    "    condition = \"greater\"\n",
    "else:\n",
    "    condition = \"less\"\n",
    "\n",
    "print(\"Male Income (\", MaleIncome ,\") is \" + condition + \" than Female Income (\", FemaleIncome, \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking solely on gender we can see that it is more likely for a man to have an income of >50k compared to that of a woman. We will now examine if this holds true when women has higher education compared to the male."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Gender = df_orig[[\"sex\", \"education\"]]\n",
    "GenderIncome_model.fit(X=X_Gender, y=Y_Income)\n",
    "\n",
    "FemaleIncome = GenderIncome_model.predict( X=[[0,15]] )[0] # Female with Doctorate\n",
    "MaleIncome = GenderIncome_model.predict( X=[[1,8]])[0] # Male with only HS education\n",
    "condition = \"\"\n",
    "if MaleIncome > FemaleIncome:\n",
    "    condition = \"greater\"\n",
    "else:\n",
    "    condition = \"less\"\n",
    "\n",
    "print(\"Male Income (\", MaleIncome ,\") is \" + condition + \" than Female Income (\", FemaleIncome, \")\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above linear regression, we can see that a female who has a doctorate is predicted to earn less than a Male who is a High School graduate without any other form of higher education. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_small = df_orig.iloc[:,[0,1,2,3,4,5,6,14]]\n",
    "correlation_mat = df_small.corr()\n",
    "sns.heatmap(correlation_mat, annot = True)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = df_orig.iloc[:,[7,8,9,10,11,12,13,14]]\n",
    "correlation_mat = df_small.corr()\n",
    "sns.heatmap(correlation_mat, annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We see that age, education, marital status, relationship, sex, capital gain, capital loss, hours per week are all correlated to class(our income variable). The rest are relatively low so ignored for now.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The relationship between people earn less than 50k and greater than 50k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.2,rc={\"figure.dpi\":300})\n",
    "df_orig['class'].value_counts().plot(kind='bar', figsize=(15, 6), rot=0)\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count of People\")\n",
    "plt.title(\"The number of people who earn less than 50k and greater than 50k\")\n",
    "class_list_new = [0]*len(class_list)\n",
    "for i,x in enumerate(list(df_orig['class'].value_counts().index)):\n",
    "    class_list_new[i] = class_list[x]\n",
    "plt.xticks(range(len(class_list)),class_list_new)\n",
    "for i,data in enumerate(list(df_orig['class'].value_counts())):\n",
    "    plt.text(x=i , y =data , s=f\"{data}\" , fontdict=dict(fontsize=16), horizontalalignment='center',\n",
    "     verticalalignment='bottom')\n",
    "plt.show()\n",
    "print(\"We can see that there are more people who earn <=50k than people who earn 50k+ in the dataset, which means that there are\", round(df_orig['class'].value_counts()[0]\\\n",
    "      /df_orig['class'].value_counts()[1], 2), \"times more people who earn <=50k than people who earn >50k.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed by Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_orig['Age'].value_counts().plot(kind='bar', figsize=(25, 8), rot=10)\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Count of People\")\n",
    "plt.title(\"Number of people by age\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = sns.displot(data=df_orig, x=\"Age\", binwidth=1, hue=\"class\")\n",
    "graph.fig.set_size_inches(20,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph shows that younger people earn less than 50k and people who are between 30 and 50 years old make more than 50k. We conclude that despite the fact that the graph has less people who earn >50k than people who earn <=50k, since there are 3.15 times more people who earn <=50k than people who earn >50k.\n",
    "\n",
    "According to this article: \"Retirement age in US rises to 61 (from 57 in the early 90s)\" (https://www.today.com/money/retirement-age-us-rises-61-57-early-90s-1c9959555), the retirement age was 60 in 1995 (the dataset is 1994 census data), so we can bin 60+ years-old as retirement age.\n",
    "We are going to create 10-year-bins later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed by workclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig[' workclass'].value_counts().plot(kind='bar', figsize=(12, 5), rot=30)\n",
    "plt.xlabel(\"Workclass\")\n",
    "plt.ylabel(\"Count of People\")\n",
    "plt.title(\"Number of people by workclass\")\n",
    "workclass_list_new = [0]*len(workclass_list)\n",
    "for i,x in enumerate(list(df_orig[' workclass'].value_counts().index)):\n",
    "    workclass_list_new[i] = workclass_list[x]\n",
    "plt.xticks(range(len(workclass_list)),workclass_list_new)\n",
    "for i,data in enumerate(list(df_orig[' workclass'].value_counts())):\n",
    "    plt.text(x=i , y =data , s=f\"{data}\" , fontdict=dict(fontsize=10), horizontalalignment='center',\n",
    "     verticalalignment='bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,6)\n",
    "sns.histplot(data=df_orig, x=\" workclass\", binwidth=1, hue=\"class\", multiple=\"fill\",discrete=True)\n",
    "plt.xticks(range(len(workclass_list)),workclass_list,rotation='vertical')\n",
    "plt.ylabel('Ratio of \">50k : <=50k\"')\n",
    "plt.title(\"Workclass\")\n",
    "plt.legend([' >50K', ' <=50K'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 1994, people whose work class is self-emp-inc earn most, which over 50% of people whose work class is self-emp-inc earn over 50k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed by education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig['education'].value_counts().plot(kind='bar', figsize=(20, 5), rot=75)\n",
    "plt.xlabel(\"Education\")\n",
    "plt.ylabel(\"Count of People\")\n",
    "plt.title(\"Number of people by education\")\n",
    "education_list_new = [0]*len(education_list)\n",
    "for i,x in enumerate(list(df_orig['education'].value_counts().index)):\n",
    "    education_list_new[i] = education_list[x]\n",
    "plt.xticks(range(len(education_list)),education_list_new)\n",
    "for i,data in enumerate(list(df_orig['education'].value_counts())):\n",
    "    plt.text(x=i , y =data , s=f\"{data}\" , fontdict=dict(fontsize=10), horizontalalignment='center',\n",
    "     verticalalignment='bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df_orig, x=\"education\", binwidth=1, hue=\"class\", multiple=\"fill\", discrete=True)\n",
    "plt.xticks(range(len(education_list)),education_list,rotation='vertical')\n",
    "plt.ylabel('Ratio of \">50k : <=50k\"')\n",
    "plt.title(\"Education\")\n",
    "plt.legend([' >50K', ' <=50K'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph says that people who have Bachelors or higher degree have higher possibilities that people can earn over 50k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed by marital status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig['marital-status'].value_counts().plot(kind='bar', figsize=(16, 5), rot=7)\n",
    "plt.xlabel(\"Marital Status\")\n",
    "plt.ylabel(\"Count of People\")\n",
    "plt.title(\"Number of people by marital status\")\n",
    "marital_list_new = [0]*len(marital_list)\n",
    "for i,x in enumerate(list(df_orig['marital-status'].value_counts().index)):\n",
    "    marital_list_new[i] = marital_list[x]\n",
    "plt.xticks(range(len(marital_list)),marital_list_new)\n",
    "for i,data in enumerate(list(df_orig['marital-status'].value_counts())):\n",
    "    plt.text(x=i , y =data , s=f\"{data}\" , fontdict=dict(fontsize=12), horizontalalignment='center',\n",
    "     verticalalignment='bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df_orig, x=\"marital-status\", binwidth=1, hue=\"class\", multiple=\"fill\", discrete=True)\n",
    "plt.xticks(range(len(marital_list)),marital_list,rotation='vertical')\n",
    "plt.ylabel('Ratio of \">50k : <=50k\"')\n",
    "plt.title(\"Marital-status\")\n",
    "plt.legend([' >50K', ' <=50K'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph says that people who live with their partner earn more money."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed by occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig['occupation'].value_counts().plot(kind='bar', figsize=(14, 6), rot=70)\n",
    "plt.xlabel(\"Occupation\")\n",
    "plt.ylabel(\"Count of People\")\n",
    "plt.title(\"Number of people by occupation\")\n",
    "occupation_list_new = [0]*len(occupation_list)\n",
    "for i,x in enumerate(list(df_orig['occupation'].value_counts().index)):\n",
    "    occupation_list_new[i] = occupation_list[x]\n",
    "plt.xticks(range(len(occupation_list)),occupation_list_new)\n",
    "for i,data in enumerate(list(df_orig['occupation'].value_counts())):\n",
    "    plt.text(x=i , y =data , s=f\"{data}\" , fontdict=dict(fontsize=10), horizontalalignment='center',\n",
    "     verticalalignment='bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df_orig, x=\"occupation\", binwidth=1, hue=\"class\", multiple=\"fill\", discrete=True)\n",
    "plt.xticks(range(len(occupation_list)),occupation_list,rotation='vertical')\n",
    "plt.ylabel('Ratio of \">50k : <=50k\"')\n",
    "plt.title(\"Occupation\")\n",
    "plt.legend([' >50K', ' <=50K'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph says that Exec-managerial, Prof-specialty, Protective-serv, and Tech-support are the most highest possibility that people earn over 50k.\n",
    "\n",
    "From the most part, we expected this data because occupations that can be categorized as white collar earn, on average, more than occupations that have been traditionally seen as blue collar. In addition, it is intresting to see that Armed Forces is actually one of the lower earning occupations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed by race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_orig['race'].value_counts().plot(kind='bar', figsize=(15, 5), rot=0)\n",
    "plt.xlabel(\"Race\")\n",
    "plt.ylabel(\"Count of People\")\n",
    "plt.title(\"Number of people by race\")\n",
    "race_list_new = [0]*len(race_list)\n",
    "for i,x in enumerate(list(df_orig['race'].value_counts().index)):\n",
    "    race_list_new[i] = race_list[x]\n",
    "plt.xticks(range(len(race_list)),race_list_new)\n",
    "for i,data in enumerate(list(df_orig['race'].value_counts())):\n",
    "    plt.text(x=i , y =data , s=f\"{data}\" , fontdict=dict(fontsize=15), horizontalalignment='center',\n",
    "     verticalalignment='bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.histplot(data=df_orig, x=\"race\", binwidth=1, hue=\"class\", multiple=\"fill\", discrete=True)\n",
    "plt.xticks(range(len(race_list)),race_list,rotation='vertical')\n",
    "plt.ylabel('Ratio of \">50k : <=50k\"')\n",
    "plt.title(\"Race\")\n",
    "plt.legend([' >50K', ' <=50K'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph says that both Asian-Pac-Islander and White people have higher possibility that they can earn over 50k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed by sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig['sex'].value_counts().plot(kind='bar', figsize=(15, 5), rot=0)\n",
    "plt.xlabel(\"Sex\")\n",
    "plt.ylabel(\"Count of People\")\n",
    "plt.title(\"Number of people by sex\")\n",
    "sex_list_new = [0]*len(sex_list)\n",
    "for i,x in enumerate(list(df_orig['sex'].value_counts().index)):\n",
    "    sex_list_new[i] = sex_list[x]\n",
    "plt.xticks(range(len(sex_list)),sex_list_new)\n",
    "for i,data in enumerate(list(df_orig['sex'].value_counts())):\n",
    "    plt.text(x=i , y =data , s=f\"{data}\" , fontdict=dict(fontsize=20), horizontalalignment='center',\n",
    "     verticalalignment='bottom')\n",
    "plt.show()\n",
    "print(\"We can see that there are\", round(list(df_orig['sex'].value_counts())[0]\\\n",
    "      /list(df_orig['sex'].value_counts())[1], 2), \"times more male than female.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df_orig, x=\"sex\", binwidth=1, hue=\"class\", multiple=\"fill\", discrete=True)\n",
    "plt.xticks(range(len(sex_list)),sex_list,rotation='vertical')\n",
    "plt.ylabel('Ratio of \">50k : <=50k\"')\n",
    "plt.title(\"Sex\")\n",
    "plt.legend([' >50K', ' <=50K'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph says that men have more possibility that they can earn over 50k than women."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sex and Race VS Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prelogue\n",
    "\n",
    "In this section we will examine class as it relates to sex and race. Class relates to a person's income and it is seperated into two parts: <=50k and >50k. Throughout this section we will refer to <50k as 0 and >50k as 1. Race has five groupings: Other, American Indian/Eskimo, Asian/Pacific Islander, Black, and White. Respectively, we will occasionally map race from 0-4 in the order they are listed. Sex has two groupings: Male and Female. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first create a **categorical plot** that will examine class as it relates to race and gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.read_csv(\"adult.csv\")\n",
    "df_temp[\"class\"].replace(class_list,\n",
    "                        range(len(class_list)), inplace=True)\n",
    "df_temp[\"education\"] = df_temp[\"education\"].replace([\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.catplot(x=\"class\", y = \"race\",\n",
    "            col=\"sex\",\n",
    "            data = df_temp,\n",
    "            orient=\"h\", height=5, aspect=1, palette=\"tab10\",\n",
    "            kind=\"violin\", dodge=True, cut=0, bw=.2\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although our plot above is not the most discernible, we can still see that White and Asian/Pacific Islander men have the greatest raw number that have an income of greater than 50,000 in income. This is because these groups have the thickest line when class is equalled to 1. As we mentioned, a class value of 1 represents making over 50,000 in income. In addition, from this plot we can also see that there is a an equal or greater raw number of men of all races that make more than 50,000 than women of any race.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will attempt to visualize this came data using a model that is easier to comprehend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(\n",
    "    data=df_temp, x=\"race\", y=\"class\", col=\"sex\",\n",
    "    kind=\"bar\", height=10, aspect=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph above, it is now easier to see that White and Asian/Pacific Islander men have by far, on average, have a greater income than any other group. Even more suprisingly, Asian/Pacific Islander men and women are actually out earning on average White men and women. This is suprising because if we group Asian/Pacific Islanders with all other minorities, they would be shown to be making less than Whites. Furthermore, from this graph we see that the lowest two earning race of men(American Indian/Eskimo and Other), are in par with the highest earning race of women (White and Asian/Pacific Islanders). This shows that across the board men are out earning women."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now represent this information as a kde plot to see if the given model will show similar results from the graph above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.race.replace([' Other',' Amer-Indian-Eskimo', ' Asian-Pac-Islander',' Black', ' White'], [0,1,2,3,4],inplace=True)\n",
    "kdplt = sns.kdeplot(data=df_temp, x=\"class\", y=\"race\", hue=\"sex\")\n",
    "sns.move_legend(kdplt, \"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above model is a KDE plot which shows the density of the give parameters. This model shows an intresting story because, although previously we saw that Asian/Pacific Islander men had a significantly higher average of people making more than 50,000 a year compared to Black men, this plot shows that the raw number of Asian/Pacific Islander men making over 50,000 a year is around the same as Black men. The difference being is that there is a siginificantly larger raw amount of Black men making 50,000 or less a year than Asian/Pacific Islander men. In addition, we can see that there is a very few raw number of women making over 50,000 in income, with the exception being White women. In addition, it is easy to assume there is a contradiction in our data given that the second graph showed Asian/Pacific Islander women out earning White women, while the third graph had no representation of Asian/Pacific Islander women making more than 50,000 annually. There is no contradiction, the reason the data is dispalyed like this is because White, by raw numbers, are heavely more represented in our data than Asian/Pacific Islander women. This plays an important role because, as mentioned, KDE graphs deal with density. So while there are, in raw numbers, more White women making 50k than their Asian counterpart, there are also more White women making 50k or under. The lack of representation of certain groups in the census also causes them to not be will represented in our kde graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Techniques Used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN First Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits rows to create a train and test\n",
    "train,test=train_test_split(df_orig.iloc[:,[4,8,9,14]],test_size=0.33)\n",
    "#train,test=train_test_split(df_orig.iloc[:,[0,1,4,5,6,7,8,9,12,13,14]],test_size=0.33)\n",
    "X_train=train.iloc[:,:3] #Take train portion and first columns\n",
    "Y_train=train.iloc[:,3:].values.ravel() #target we are trying to predict for\n",
    "X_test=test.iloc[:,:3] #take test portion columns \n",
    "Y_test=test.iloc[:,3:].values.ravel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a training and test set here. We split each set to have features for training and one label. We can use this data to run into our following model. We picked categorical features with some correlation to ensure there are no difficulties from mixing categorical and numeric variables. As a benchmark and first try, we run a KNN model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=KNeighborsClassifier(\n",
    "    n_neighbors=80, \n",
    "    weights='uniform', \n",
    "    algorithm='auto', \n",
    "    leaf_size=30, \n",
    "    p=2, \n",
    "    #metric='matching', \n",
    "    metric='minkowski', \n",
    "    metric_params=None, \n",
    "    n_jobs=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notably we use minkowski metric as opposed to matching. Most of this is straight from sklearn documentation however we adjusted n_neighbors to be the sqrt of the dataset size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test=knn.predict(X_test)\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, pred_test))\n",
    "print(\"Precision:\",metrics.precision_score(Y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "78% accuracy to begin with. This seemed promising. We wanted to see the results through a precision and recall curve which follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = metrics.PrecisionRecallDisplay.from_predictions(Y_test, pred_test, name=\"kNN\")\n",
    "display.ax_.set_title(\"2-class Precision-Recall curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = metrics.precision_recall_curve(Y_test,pred_test)\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.roc_curve(Y_test,pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TN, FP, FN, TP =metrics.confusion_matrix(Y_test, pred_test).ravel()\n",
    "\n",
    "\n",
    "TPR = TP/(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "# False discovery rate\n",
    "FDR = FP/(TP+FP)\n",
    "\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=metrics.confusion_matrix(Y_test, pred_test),display_labels=knn.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Attempt Random Forest \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits rows to create a train and test\n",
    "#0,4,7,9,10,11,12\n",
    "#0,1,3,5,6,7,8,9,12,13,14 DO NOT DELETE, CAN USE THIS LATER FOR IMAGE/SLIDES\n",
    "#[0,1,4,6,7,8,9,10,11,12,14]] 85%\n",
    "#168\n",
    "train,test=train_test_split(df_orig.iloc[:,[0,1,4,6,7,8,9,10,11,12,14]],test_size=0.2)\n",
    "X_train=train.iloc[:,:10].to_numpy() #Take train portion and first columns\n",
    "Y_train=train.iloc[:,10:].values.ravel() #target we are trying to predict for\n",
    "X_test=test.iloc[:,0:10].to_numpy()#take test portion columns \n",
    "Y_test=test.iloc[:,10:].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100,\n",
    "                            # criterion='gini', \n",
    "                            max_depth=None, \n",
    "                            # min_samples_split=2, \n",
    "                            # min_samples_leaf=1, \n",
    "                            # min_weight_fraction_leaf=0.0,\n",
    "                            # max_features='sqrt',\n",
    "                            # max_leaf_nodes=None, \n",
    "                            # min_impurity_decrease=0.0, \n",
    "                            # bootstrap=True, \n",
    "                            # oob_score=False, \n",
    "                            # n_jobs=None, \n",
    "                            # random_state=None, \n",
    "                            # verbose=0,\n",
    "                            # warm_start=False, \n",
    "                            # class_weight=None,\n",
    "                            # ccp_alpha=0.0, \n",
    "                            # max_samples=None\n",
    "                            )\n",
    "rf.fit(X_train,Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test=rf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, pred_test))\n",
    "print(\"Precision:\",metrics.precision_score(Y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Data Processing Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features=df_orig.iloc[:,[0,1,4,6,7,8,9,10,11,12,14]].copy()\n",
    "df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize capital gain and capital loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max(normalize( df_features[\"capital-gain\"].to_numpy().reshape(1,-1)))\n",
    "#scaler=StandardScaler()\n",
    "##scaler.fit()\n",
    "#scaler.fit_transform(df_features[\"capital-gain\"].to_numpy().reshape(1,-1)).reshape(df_features[\"capital-gain\"].shape)\n",
    "#scaler.fit_transform(X_train.reshape(-1,X_train.shape[-1])).reshape(X_train.shape)\n",
    "#df_features\n",
    "\n",
    "#df_features[[\"capital-gain\", \"capital-loss\"]] = StandardScaler.fit_transform(X=df_features[[\"capital-gain\", \"capital-loss\"]],y=df_features[[\"capital-gain\", \"capital-loss\"]])\n",
    "df_features[[\"capital-gain\"]]=df_features[[\"capital-gain\"]].astype(float)\n",
    "df_features[[\"capital-loss\"]]=df_features[[\"capital-loss\"]].astype(float)\n",
    "# Min-Max Normalization\n",
    "\n",
    "cap_gain= df_features[[\"capital-gain\", \"capital-loss\"]] \n",
    "\n",
    "df_features=df_features.drop(\"capital-gain\", axis=1)\n",
    "df_features=df_features.drop(\"capital-loss\", axis=1)\n",
    "#df_features.drop(\"capital-loss\", axis=1)\n",
    "df_norm = (cap_gain-cap_gain.min())/(cap_gain.max()-cap_gain.min())\n",
    "df_features = pd.concat((df_norm, df_features), 1)\n",
    " \n",
    "# print(\"Scaled Dataset Using Pandas\")\n",
    "# df_norm.head()\n",
    "\n",
    "df_features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new boolean variable loss/gain for whether they did either "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.insert(loc=9, column='loss/gain', value=0)\n",
    "df_features['loss/gain'] = np.where(((df_features['capital-loss']==0) & (df_features['capital-gain']==0)), 0, 1)\n",
    "df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning Age Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.insert(loc=10, column='Age Group', value=0)\n",
    "df_features['Age Group'] = pd.cut(\n",
    "    df_features['Age'], \n",
    "    [0,29, 44, 60,100], \n",
    "    labels=[0, 1,2,3]\n",
    ")\n",
    "df_features[\"Age Group\"]=pd.to_numeric(df_features[\"Age Group\"])\n",
    "df_features=df_features.drop(\"Age\", axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binning Hours worked per week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features[\"hours-per-week\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.insert(loc=10, column='HrsWorked', value=0)\n",
    "df_features['HrsWorked'] = pd.cut(\n",
    "    df_features['hours-per-week'], \n",
    "    [0,20, 40, 60,100], \n",
    "    labels=[0, 1,2,3]\n",
    ")\n",
    "df_features[\"HrsWorked\"]=pd.to_numeric(df_features[\"HrsWorked\"])\n",
    "df_features=df_features.drop(\"hours-per-week\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdf=pd.get_dummies(df_features.relationship)\n",
    "\n",
    "tmpdf.columns=[\"Husband\",\"Not-in-family\",\"Other-relative\",\"Own-child\",\"Unmarried\",\"Wife\"]\n",
    "df_features = pd.concat((tmpdf, df_features), 1)\n",
    "#df_features=df_features.drop(\"relationship\", axis=1)\n",
    "df_features=df_features.drop(\"Other-relative\", axis=1)\n",
    "tmpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdf=pd.get_dummies(df_features.race,prefix=\"race\")\n",
    "tmpdf.columns=[\"Amer-Indian-Eskimo\", \"Asian-Pac-Islander\",\"Black\",\"Other\",\"White\"]\n",
    "df_features = pd.concat((tmpdf, df_features), 1)\n",
    "df_features=df_features.drop(\"Amer-Indian-Eskimo\", axis=1)\n",
    "df_features=df_features.drop(\"Asian-Pac-Islander\", axis=1)\n",
    "df_features=df_features.drop(\"race\", axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to modify these values and see if we can increase correlation. \n",
    "We employ methods such as normalization and binning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = df_features.iloc[:,:]\n",
    "\n",
    "correlation_mat = df_small.corr()\n",
    "sns.heatmap(correlation_mat, annot = True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models Round 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_features=df_features.drop(\"capital-gain\", axis=1)\n",
    "# df_features=df_features.drop(\"capital-loss\", axis=1)\n",
    "\n",
    "train,test=train_test_split(df_features,test_size=0.2)\n",
    "X_train=train.iloc[:,:18].to_numpy() #Take train portion and first columns\n",
    "Y_train=train.iloc[:,18:].values.ravel() #target we are trying to predict for\n",
    "X_test=test.iloc[:,0:18].to_numpy()#take test portion columns \n",
    "Y_test=test.iloc[:,18:].values.ravel()\n",
    "rf = RandomForestClassifier(n_estimators=100,\n",
    "                            # criterion='gini', \n",
    "                            max_depth=None, \n",
    "                            # min_samples_split=2, \n",
    "                            # min_samples_leaf=1, \n",
    "                            # min_weight_fraction_leaf=0.0,\n",
    "                            # max_features='sqrt',\n",
    "                            # max_leaf_nodes=None, \n",
    "                            # min_impurity_decrease=0.0, \n",
    "                            # bootstrap=True, \n",
    "                            # oob_score=False, \n",
    "                            # n_jobs=None, \n",
    "                            # random_state=None, \n",
    "                            # verbose=0,\n",
    "                            # warm_start=False, \n",
    "                            # class_weight=None,\n",
    "                            # ccp_alpha=0.0, \n",
    "                            # max_samples=None\n",
    "                            )\n",
    "rf.fit(X_train,Y_train)\n",
    "pred_test=rf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, pred_test))\n",
    "print(\"Precision:\",metrics.precision_score(Y_test, pred_test))\n",
    "#.85659450\n",
    "#0.8588975894365116 after removing age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running kNN with same dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = rf.feature_importances_.argsort()\n",
    "plt.barh(df_features.columns[indexes], rf.feature_importances_[indexes])\n",
    "plt.xlabel(\"Random Forest Feature Importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=KNeighborsClassifier(\n",
    "    n_neighbors=80, \n",
    "    weights='uniform', \n",
    "    algorithm='auto', \n",
    "    leaf_size=30, \n",
    "    p=2, \n",
    "    #metric='matching', \n",
    "    metric='minkowski', \n",
    "    metric_params=None, \n",
    "    n_jobs=None)\n",
    "knn.fit(X_train,Y_train)\n",
    "pred_test=knn.predict(X_test)\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, pred_test))\n",
    "print(\"Precision:\",metrics.precision_score(Y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Project Proposal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "a8e0ba2ee76e786137407659e0a1b83380950342a0397d9067fd9b1edc172808"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
