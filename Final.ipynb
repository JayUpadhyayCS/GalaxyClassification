{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contributors\n",
    "### Jay Upadhyay\n",
    "### Haruki Miyazaki\n",
    "###\n",
    "###\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig=pd.read_csv(\"adult.csv\")\n",
    "df_orig.dropna(inplace=True)\n",
    "df_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Project Proposal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pulled the data from https://archive-beta.ics.uci.edu/dataset/2/adult ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Collection and data cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing workclass to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workclass_list = list(sorted(set(df_orig[\" workclass\"])))\n",
    "\n",
    "for i,x in enumerate(workclass_list):\n",
    "    print(i,\":\", x)\n",
    "    \n",
    "df_orig[' workclass'].replace(workclass_list,\n",
    "                        range(len(workclass_list)), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing Education to Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig['education'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_list=[ ' Preschool',' 1st-4th',' 5th-6th',' 7th-8th',' 9th',' 10th',' 11th',' 12th',' HS-grad',\n",
    "                              ' Assoc-voc',' Assoc-acdm',' Some-college',' Bachelors', ' Masters',\n",
    "                              ' Prof-school' ,' Doctorate']\n",
    "\n",
    "df_orig['education'].replace(education_list,\n",
    "                        range(16), inplace=True)\n",
    "\n",
    "df_orig\n",
    "for x in range(16):\n",
    "    print(x,\":\", education_list[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note. I want to come back to this and bin it into appropriate \n",
    "I also chose to exclude this for now because I believe education-num already represents it numerically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing marital status to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marital_list = list(sorted(set(df_orig[\"marital-status\"])))\n",
    "\n",
    "for i,x in enumerate(marital_list):\n",
    "    print(i,\":\", x)\n",
    "\n",
    "df_orig['marital-status'].replace(marital_list,\n",
    "                        range(len(marital_list)), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Occupation\n",
    "\n",
    "I don't like the ? mark section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupation_list = list(sorted(set(df_orig[\"occupation\"])))\n",
    "\n",
    "for i,x in enumerate(occupation_list):\n",
    "    print(i,\":\", x)\n",
    "\n",
    "df_orig['occupation'].replace(occupation_list,\n",
    "                        range(len(occupation_list)), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationship conversion to numeric\n",
    "\n",
    "I don't like other relative section here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship_list = list(sorted(set(df_orig[\"relationship\"])))\n",
    "\n",
    "for i,x in enumerate(relationship_list):\n",
    "    print(i,\":\", x)\n",
    "\n",
    "df_orig['relationship'].replace(relationship_list,\n",
    "                        range(len(relationship_list)), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race conversion to numeric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_list = list(sorted(set(df_orig[\"race\"])))\n",
    "\n",
    "for i,x in enumerate(race_list):\n",
    "    print(i,\":\", x)\n",
    "\n",
    "df_orig['race'].replace(race_list,\n",
    "                        range(len(race_list)), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sex conversion to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_list = list(sorted(set(df_orig[\"sex\"])))\n",
    "\n",
    "for i,x in enumerate(sex_list):\n",
    "    print(i,\":\", x)\n",
    "\n",
    "df_orig['sex'].replace(sex_list,\n",
    "                        range(len(sex_list)), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country to Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing a column \"class\" to be 0:<=50K and 1:>50K\n",
    "country_list = list(sorted(set(df_orig[\"native-country\"])))\n",
    "\n",
    "for i,x in enumerate(country_list):\n",
    "    print(i,\":\", x)\n",
    "\n",
    "df_orig['native-country'].replace(country_list,\n",
    "                        range(len(country_list)), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Income to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing a column \"class\" to be 0:<=50K and 1:>50K\n",
    "class_list = list(sorted(set(df_orig[\"class\"])))\n",
    "\n",
    "for i,x in enumerate(class_list):\n",
    "    print(i,\":\", x)\n",
    "    \n",
    "df_orig['class'].replace(class_list,\n",
    "                        range(len(class_list)), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_small = df_orig.iloc[:,[0,1,2,3,4,5,6,14]]\n",
    "correlation_mat = df_small.corr()\n",
    "sns.heatmap(correlation_mat, annot = True)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = df_orig.iloc[:,[7,8,9,10,11,12,13,14]]\n",
    "correlation_mat = df_small.corr()\n",
    "sns.heatmap(correlation_mat, annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We see that age, education, marital status, relationship, sex, capital gain, capital loss, hours per week are all correlated to class(our income variable). The rest are relatively low so ignored for now.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Techniques Used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN First Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits rows to create a train and test\n",
    "train,test=train_test_split(df_orig.iloc[:,[4,8,9,14]],test_size=0.33)\n",
    "#train,test=train_test_split(df_orig.iloc[:,[0,1,4,5,6,7,8,9,12,13,14]],test_size=0.33)\n",
    "X_train=train.iloc[:,:3] #Take train portion and first columns\n",
    "Y_train=train.iloc[:,3:].values.ravel() #target we are trying to predict for\n",
    "X_test=test.iloc[:,:3] #take test portion columns \n",
    "Y_test=test.iloc[:,3:].values.ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=KNeighborsClassifier(\n",
    "    n_neighbors=80, \n",
    "    weights='uniform', \n",
    "    algorithm='auto', \n",
    "    leaf_size=30, \n",
    "    p=2, \n",
    "    #metric='matching', \n",
    "    metric='minkowski', \n",
    "    metric_params=None, \n",
    "    n_jobs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test=knn.predict(X_test)\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, pred_test))\n",
    "print(\"Precision:\",metrics.precision_score(Y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = metrics.PrecisionRecallDisplay.from_predictions(Y_test, pred_test, name=\"kNN\")\n",
    "display.ax_.set_title(\"2-class Precision-Recall curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = metrics.precision_recall_curve(Y_test,pred_test)\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.roc_curve(Y_test,pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Attempt Random Forest \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits rows to create a train and test\n",
    "#0,4,7,9,10,11,12\n",
    "#0,1,3,5,6,7,8,9,12,13,14 DO NOT DELETE, CAN USE THIS LATER FOR IMAGE/SLIDES\n",
    "#[0,1,4,6,7,8,9,10,11,12,14]] 85%\n",
    "#168\n",
    "train,test=train_test_split(df_orig.iloc[:,[0,1,4,6,7,8,9,10,11,12,14]],test_size=0.2)\n",
    "X_train=train.iloc[:,:10].to_numpy() #Take train portion and first columns\n",
    "Y_train=train.iloc[:,10:].values.ravel() #target we are trying to predict for\n",
    "X_test=test.iloc[:,0:10].to_numpy()#take test portion columns \n",
    "Y_test=test.iloc[:,10:].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100,\n",
    "                            # criterion='gini', \n",
    "                            max_depth=None, \n",
    "                            # min_samples_split=2, \n",
    "                            # min_samples_leaf=1, \n",
    "                            # min_weight_fraction_leaf=0.0,\n",
    "                            # max_features='sqrt',\n",
    "                            # max_leaf_nodes=None, \n",
    "                            # min_impurity_decrease=0.0, \n",
    "                            # bootstrap=True, \n",
    "                            # oob_score=False, \n",
    "                            # n_jobs=None, \n",
    "                            # random_state=None, \n",
    "                            # verbose=0,\n",
    "                            # warm_start=False, \n",
    "                            # class_weight=None,\n",
    "                            # ccp_alpha=0.0, \n",
    "                            # max_samples=None\n",
    "                            )\n",
    "rf.fit(X_train,Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test=rf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, pred_test))\n",
    "print(\"Precision:\",metrics.precision_score(Y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Data Processing Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features=df_orig.iloc[:,[0,1,4,6,7,8,9,10,11,12,14]].copy()\n",
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max(normalize( df_features[\"capital-gain\"].to_numpy().reshape(1,-1)))\n",
    "#scaler=StandardScaler()\n",
    "##scaler.fit()\n",
    "#scaler.fit_transform(df_features[\"capital-gain\"].to_numpy().reshape(1,-1)).reshape(df_features[\"capital-gain\"].shape)\n",
    "#scaler.fit_transform(X_train.reshape(-1,X_train.shape[-1])).reshape(X_train.shape)\n",
    "#df_features\n",
    "\n",
    "#df_features[[\"capital-gain\", \"capital-loss\"]] = StandardScaler.fit_transform(X=df_features[[\"capital-gain\", \"capital-loss\"]],y=df_features[[\"capital-gain\", \"capital-loss\"]])\n",
    "df_features[[\"capital-gain\"]]=df_features[[\"capital-gain\"]].astype(float)\n",
    "df_features[[\"capital-loss\"]]=df_features[[\"capital-loss\"]].astype(float)\n",
    "# Min-Max Normalization\n",
    "\n",
    "cap_gain= df_features[[\"capital-gain\", \"capital-loss\"]] \n",
    "\n",
    "df_features=df_features.drop(\"capital-gain\", axis=1)\n",
    "df_features=df_features.drop(\"capital-loss\", axis=1)\n",
    "#df_features.drop(\"capital-loss\", axis=1)\n",
    "df_norm = (cap_gain-cap_gain.min())/(cap_gain.max()-cap_gain.min())\n",
    "df_features = pd.concat((df_norm, df_features), 1)\n",
    " \n",
    "# print(\"Scaled Dataset Using Pandas\")\n",
    "# df_norm.head()\n",
    "\n",
    "df_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.insert(loc=9, column='loss/gain', value=0)\n",
    "df_features['loss/gain'] = np.where(((df_features['capital-loss']==0) & (df_features['capital-gain']==0)), 0, 1)\n",
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.insert(loc=10, column='Age Group', value=0)\n",
    "df_features['Age Group'] = pd.cut(\n",
    "    df_features['Age'], \n",
    "    [0,29, 44, 60,100], \n",
    "    labels=[0, 1,2,3]\n",
    ")\n",
    "df_features[\"Age Group\"]=pd.to_numeric(df_features[\"Age Group\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to modify these values and see if we can increase correlation. \n",
    "We employ methods such as normalization and binning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = df_features.iloc[:,:]\n",
    "\n",
    "correlation_mat = df_small.corr()\n",
    "sns.heatmap(correlation_mat, annot = True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models Round 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_features=df_features.drop(\"capital-gain\", axis=1)\n",
    "# df_features=df_features.drop(\"capital-loss\", axis=1)\n",
    "df_features=df_features.drop(\"Age\", axis=1)\n",
    "train,test=train_test_split(df_features,test_size=0.2)\n",
    "X_train=train.iloc[:,:11].to_numpy() #Take train portion and first columns\n",
    "Y_train=train.iloc[:,11:].values.ravel() #target we are trying to predict for\n",
    "X_test=test.iloc[:,0:11].to_numpy()#take test portion columns \n",
    "Y_test=test.iloc[:,11:].values.ravel()\n",
    "rf = RandomForestClassifier(n_estimators=100,\n",
    "                            # criterion='gini', \n",
    "                            max_depth=None, \n",
    "                            # min_samples_split=2, \n",
    "                            # min_samples_leaf=1, \n",
    "                            # min_weight_fraction_leaf=0.0,\n",
    "                            # max_features='sqrt',\n",
    "                            # max_leaf_nodes=None, \n",
    "                            # min_impurity_decrease=0.0, \n",
    "                            # bootstrap=True, \n",
    "                            # oob_score=False, \n",
    "                            # n_jobs=None, \n",
    "                            # random_state=None, \n",
    "                            # verbose=0,\n",
    "                            # warm_start=False, \n",
    "                            # class_weight=None,\n",
    "                            # ccp_alpha=0.0, \n",
    "                            # max_samples=None\n",
    "                            )\n",
    "rf.fit(X_train,Y_train)\n",
    "pred_test=rf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, pred_test))\n",
    "print(\"Precision:\",metrics.precision_score(Y_test, pred_test))\n",
    "#.85659450\n",
    "#0.8588975894365116 after removing age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = rf.feature_importances_.argsort()\n",
    "plt.barh(df_features.columns[indexes], rf.feature_importances_[indexes])\n",
    "plt.xlabel(\"Random Forest Feature Importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Project Proposal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
